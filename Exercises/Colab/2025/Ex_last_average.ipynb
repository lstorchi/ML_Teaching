{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 180
    },
    "executionInfo": {
     "elapsed": 19452,
     "status": "ok",
     "timestamp": 1762694984962,
     "user": {
      "displayName": "Loriano Storchi",
      "userId": "02134747894945957350"
     },
     "user_tz": -60
    },
    "id": "Lac9isFcvZPv",
    "outputId": "c89b6a7c-ac51-404c-bd23-4103d682ce30"
   },
   "source": [
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
    "      name=fn, length=len(uploaded[fn])))\n",
    "\n",
    "  !ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1030,
     "status": "ok",
     "timestamp": 1762695658510,
     "user": {
      "displayName": "Loriano Storchi",
      "userId": "02134747894945957350"
     },
     "user_tz": -60
    },
    "id": "F8v7Dfz_vzdf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logBB 3608\n",
      "classes 3608\n",
      "(3608, 130)\n",
      "                        Objects        V        S        R        G         d  \\\n",
      "0  1,1,1,2-tetrachloroethane_c0  327.875  248.402  1.31994  1.12279  0.511927   \n",
      "1  1,1,1,2-tetrachloroethane_c1  327.750  249.588  1.31316  1.13127  0.512122   \n",
      "2  1,1,1,2-tetrachloroethane_c2  327.625  241.829  1.35478  1.07934  0.512318   \n",
      "3  1,1,1,2-tetrachloroethane_c3  326.250  243.898  1.33765  1.09783  0.514477   \n",
      "4  1,1,1,2-tetrachloroethane_c4  327.625  244.183  1.34172  1.09514  0.512318   \n",
      "\n",
      "        W1       W2     W3   W4  ...   P5    EMDIF    EMDIS  Sdry/S  Spol/S  \\\n",
      "0  560.000  163.875  4.875  0.0  ...  0.0  3.11199  2.80238     1.0     0.0   \n",
      "1  561.875  163.500  4.750  0.0  ...  0.0  3.11199  2.80274     1.0     0.0   \n",
      "2  550.625  162.375  4.375  0.0  ...  0.0  3.11199  2.80524     1.0     0.0   \n",
      "3  550.750  163.375  4.500  0.0  ...  0.0  3.11199  2.80523     1.0     0.0   \n",
      "4  551.375  163.000  4.500  0.0  ...  0.0  3.11199  2.80289     1.0     0.0   \n",
      "\n",
      "    FLEX_PT  PAINS  CUSTOM  logBB  Class  \n",
      "0  0.195959      0     NaN   0.33      1  \n",
      "1  0.195959      0     NaN   0.33      1  \n",
      "2  0.195959      0     NaN   0.33      1  \n",
      "3  0.195959      0     NaN   0.33      1  \n",
      "4  0.195959      0     NaN   0.33      1  \n",
      "\n",
      "[5 rows x 130 columns]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('BBB_features.csv', sep=';')\n",
    "label = pd.read_csv('BBB_labels.txt', header=None, sep=' ')\n",
    "logbb = []\n",
    "classes = []\n",
    "for molname in df['Objects']:\n",
    "    basename = re.sub(r'_c\\d+', '', molname)\n",
    "    if basename in label[0].values:\n",
    "        logBB = label[label[0] == basename][1].values[0]\n",
    "        logbb.append(logBB)\n",
    "        if logBB > 0:\n",
    "            classes.append(1)\n",
    "        else:\n",
    "            classes.append(0)\n",
    "    else:\n",
    "        print('removing', molname)\n",
    "\n",
    "df['logBB'] = logbb\n",
    "df['Class'] = classes\n",
    "\n",
    "print('logBB', len(logbb))\n",
    "print('classes', len(classes))\n",
    "print(df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "CwLAGr92wAM_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Initial X.shape (3608, 130)\n",
      "      After removing NaN columns, X.shape (3608, 127)\n",
      " After removing constant columns, X.shape (3608, 125)\n",
      "After removing duplicate columns, X.shape (3608, 125)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3608 entries, 0 to 3607\n",
      "Columns: 125 entries, Objects to Class\n",
      "dtypes: object(125)\n",
      "memory usage: 3.4+ MB\n",
      "None\n",
      "\n",
      "X columns average and std deviation:\n",
      "V: avg=552.4429, std=202.2248\n",
      "S: avg=387.4471, std=121.9283\n",
      "R: avg=1.4011, std=0.0904\n",
      "G: avg=1.2978, std=0.1389\n",
      "d: avg=0.4125, std=0.0847\n",
      "W1: avg=908.5674, std=304.8175\n",
      "W2: avg=513.3480, std=247.8358\n",
      "W3: avg=266.3081, std=161.3544\n",
      "W4: avg=108.4644, std=75.0177\n",
      "W5: avg=50.5712, std=40.3504\n",
      "W6: avg=21.2528, std=20.4407\n",
      "W7: avg=6.9407, std=9.1792\n",
      "W8: avg=1.4158, std=3.0600\n",
      "D1: avg=202.6513, std=94.3741\n",
      "D2: avg=86.4462, std=49.6445\n",
      "D3: avg=33.9245, std=22.8631\n",
      "D4: avg=18.3450, std=14.5966\n",
      "D5: avg=11.4640, std=10.0155\n",
      "D6: avg=7.4589, std=7.1735\n",
      "D7: avg=5.0156, std=5.1860\n",
      "D8: avg=3.2368, std=3.6486\n",
      "WO1: avg=52.9366, std=64.1609\n",
      "WO2: avg=15.6052, std=21.0614\n",
      "WO3: avg=4.7853, std=7.6662\n",
      "WO4: avg=0.7296, std=1.7850\n",
      "WO5: avg=0.0245, std=0.1966\n",
      "WO6: avg=0.0011, std=0.0312\n",
      "WN1: avg=314.4153, std=188.7845\n",
      "WN2: avg=130.2153, std=88.7965\n",
      "WN3: avg=58.8398, std=46.4741\n",
      "WN4: avg=23.7554, std=22.3956\n",
      "WN5: avg=6.7681, std=9.6611\n",
      "WN6: avg=1.1323, std=2.7907\n",
      "IW1: avg=0.0920, std=0.0769\n",
      "IW2: avg=0.3008, std=0.2100\n",
      "IW3: avg=0.6869, std=0.4253\n",
      "IW4: avg=0.8582, std=0.7043\n",
      "CW1: avg=2.3558, std=0.4344\n",
      "CW2: avg=1.3308, std=0.6010\n",
      "CW3: avg=0.6953, std=0.4257\n",
      "CW4: avg=0.2871, std=0.2024\n",
      "CW5: avg=0.1299, std=0.1032\n",
      "CW6: avg=0.0536, std=0.0537\n",
      "CW7: avg=0.0171, std=0.0245\n",
      "CW8: avg=0.0035, std=0.0084\n",
      "ID1: avg=0.0534, std=0.0428\n",
      "ID2: avg=0.1158, std=0.0845\n",
      "ID3: avg=0.1645, std=0.1192\n",
      "ID4: avg=0.1813, std=0.1517\n",
      "CD1: avg=0.5178, std=0.1970\n",
      "CD2: avg=0.2126, std=0.0955\n",
      "CD3: avg=0.0810, std=0.0449\n",
      "CD4: avg=0.0424, std=0.0293\n",
      "CD5: avg=0.0259, std=0.0204\n",
      "CD6: avg=0.0166, std=0.0147\n",
      "CD7: avg=0.0110, std=0.0107\n",
      "CD8: avg=0.0070, std=0.0075\n",
      "HL1: avg=4.0399, std=8.0671\n",
      "HL2: avg=3.5413, std=8.2057\n",
      "A: avg=4.1454, std=2.1888\n",
      "CP: avg=8.0752, std=17.3156\n",
      "POL: avg=24.7358, std=11.5832\n",
      "MW: avg=232.4522, std=104.2228\n",
      "FLEX: avg=1.0826, std=0.7555\n",
      "FLEX_RB: avg=0.1892, std=0.0991\n",
      "NCC: avg=0.1064, std=0.3368\n",
      "DIFF: avg=0.7155, std=0.2292\n",
      "SE: avg=9.8274, std=7.0833\n",
      "SE0: avg=7.4011, std=5.8188\n",
      "SE1: avg=2.4263, std=2.9984\n",
      "LOGP n-Oct: avg=2.5046, std=1.5542\n",
      "LOGP c-Hex: avg=1.1567, std=2.1962\n",
      "PSA: avg=41.9823, std=31.5774\n",
      "HSA: avg=345.4648, std=113.4855\n",
      "PSAR: avg=0.1085, std=0.0835\n",
      "PHSAR: avg=0.1327, std=0.1196\n",
      "LgD5: avg=0.9869, std=1.8543\n",
      "LgD6: avg=1.2082, std=1.7535\n",
      "LgD7: avg=1.5112, std=1.6734\n",
      "LgD7.5: avg=1.6683, std=1.6717\n",
      "LgD8: avg=1.8082, std=1.7036\n",
      "LgD9: avg=1.9842, std=1.8479\n",
      "LgD10: avg=1.9719, std=2.0400\n",
      "AUS7.4: avg=1.2729, std=0.7945\n",
      "%FU4: avg=49.3262, std=48.4379\n",
      "%FU5: avg=49.3187, std=48.3629\n",
      "%FU6: avg=50.4192, std=48.2294\n",
      "%FU7: avg=51.1383, std=47.1054\n",
      "%FU8: avg=53.7613, std=43.1859\n",
      "%FU9: avg=63.6836, std=38.0829\n",
      "%FU10: avg=73.4626, std=37.6620\n",
      "SOLY: avg=-2.6520, std=1.3190\n",
      "LgS3: avg=-0.7989, std=1.9572\n",
      "LgS4: avg=-0.9852, std=1.8618\n",
      "LgS5: avg=-1.1460, std=1.8142\n",
      "LgS6: avg=-1.3734, std=1.7410\n",
      "LgS7: avg=-1.6806, std=1.6533\n",
      "LgS7.5: avg=-1.8376, std=1.6347\n",
      "LgS8: avg=-1.9769, std=1.6410\n",
      "LgS9: avg=-2.1491, std=1.7257\n",
      "LgS10: avg=-2.1316, std=1.8687\n",
      "LgS11: avg=-1.9773, std=2.0384\n",
      "PB: avg=62.2761, std=24.6013\n",
      "VD: avg=0.2499, std=0.2707\n",
      "CACO2: avg=0.9166, std=0.5261\n",
      "SKIN: avg=-2.1694, std=0.9361\n",
      "MetStab: avg=69.2387, std=24.0620\n",
      "HTSflag: avg=0.0019, std=0.0440\n",
      "C1: avg=0.0218, std=0.0512\n",
      "C2: avg=0.0626, std=0.0719\n",
      "C3: avg=0.1438, std=0.0907\n",
      "C4: avg=0.5056, std=0.2593\n",
      "P2: avg=0.0050, std=0.0193\n",
      "P3: avg=0.0557, std=0.0620\n",
      "P4: avg=0.0866, std=0.0928\n",
      "P5: avg=0.0174, std=0.0281\n",
      "EMDIF: avg=5.9179, std=2.3881\n",
      "EMDIS: avg=3.5510, std=2.3255\n",
      "Sdry/S: avg=0.6459, std=0.2289\n",
      "Spol/S: avg=0.2694, std=0.1901\n",
      "FLEX_PT: avg=1.9425, std=1.6949\n",
      "PAINS: avg=0.0421, std=0.2009\n",
      "logBB: avg=0.1232, std=0.7092\n",
      "Class: avg=0.5734, std=0.4946\n"
     ]
    }
   ],
   "source": [
    "X = df\n",
    "print('                          Initial X.shape', X.shape)\n",
    "# remove columns with NaN\n",
    "X = X.dropna(axis=1)    \n",
    "print('      After removing NaN columns, X.shape', X.shape)\n",
    "# remove constant columns\n",
    "X = X.loc[:, (X != X.iloc[0]).any()]\n",
    "print(' After removing constant columns, X.shape', X.shape)\n",
    "# remove duplicate columns\n",
    "X = X.T.drop_duplicates().T\n",
    "print('After removing duplicate columns, X.shape', X.shape)\n",
    "\n",
    "print(X.info())\n",
    "# print each X column everage and std deviation\n",
    "print()\n",
    "print('X columns average and std deviation:')\n",
    "for col in X.columns:\n",
    "    if col != 'Objects':\n",
    "        print(f'{col}: avg={X[col].mean():.4f}, std={X[col].std():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After grouping by molecule:\n",
      "X.shape (330, 124)\n",
      "\n",
      "                                     V           S         R         G  \\\n",
      "Objects                                                                  \n",
      "1,1,1,2-tetrachloroethane   327.041667      246.79  1.325329  1.114763   \n",
      "1,1-difluorochloroethylene     210.125     175.335   1.19842   1.03896   \n",
      "1,2-dichloroethane             256.375     205.486   1.24765   1.08036   \n",
      "1,4-divinyloxybutane        440.890625   328.90675  1.341085   1.27213   \n",
      "1-butanol                   253.512931  205.453379  1.234237  1.092314   \n",
      "\n",
      "                                   d          W1          W2          W3  \\\n",
      "Objects                                                                    \n",
      "1,1,1,2-tetrachloroethane   0.513234  555.319444  163.611111       4.625   \n",
      "1,1-difluorochloroethylene  0.468668     540.875     335.875       190.0   \n",
      "1,2-dichloroethane          0.385992     406.875      66.625         0.0   \n",
      "1,4-divinyloxybutane        0.322572  662.398438  282.664062  112.328125   \n",
      "1-butanol                   0.292413  473.297414  273.853448   150.62069   \n",
      "\n",
      "                                   W4         W5  ...        P4   P5    EMDIF  \\\n",
      "Objects                                           ...                           \n",
      "1,1,1,2-tetrachloroethane         0.0        0.0  ...       0.0  0.0  3.11199   \n",
      "1,1-difluorochloroethylene      79.75       16.0  ...       0.0  0.0  3.63672   \n",
      "1,2-dichloroethane                0.0        0.0  ...       0.0  0.0  1.50746   \n",
      "1,4-divinyloxybutane          41.0625  15.398438  ...       0.0  0.0  2.50582   \n",
      "1-butanol                   68.491379  33.206897  ...  0.166667  0.0  3.90329   \n",
      "\n",
      "                               EMDIS    Sdry/S    Spol/S   FLEX_PT PAINS  \\\n",
      "Objects                                                                    \n",
      "1,1,1,2-tetrachloroethane   2.804057       1.0       0.0  0.195959   0.0   \n",
      "1,1-difluorochloroethylene   1.35907  0.522885  0.432101       0.0   0.0   \n",
      "1,2-dichloroethane            2.2557       1.0       0.0       0.5   0.0   \n",
      "1,4-divinyloxybutane        2.889677  0.699959  0.118851   5.53399   0.0   \n",
      "1-butanol                   1.418883  0.526972  0.316595   2.23607   0.0   \n",
      "\n",
      "                           logBB Class  \n",
      "Objects                                 \n",
      "1,1,1,2-tetrachloroethane   0.33   1.0  \n",
      "1,1-difluorochloroethylene -0.02   0.0  \n",
      "1,2-dichloroethane         -0.14   0.0  \n",
      "1,4-divinyloxybutane        0.12   1.0  \n",
      "1-butanol                  -0.02   0.0  \n",
      "\n",
      "[5 rows x 124 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 330 entries, 1,1,1,2-tetrachloroethane to zolpidem\n",
      "Columns: 124 entries, V to Class\n",
      "dtypes: object(124)\n",
      "memory usage: 322.3+ KB\n",
      "None\n",
      "\n",
      "X columns average and std deviation:\n",
      "V: avg=565.7422, std=234.3231\n",
      "S: avg=394.7573, std=141.9448\n",
      "R: avg=1.4015, std=0.1019\n",
      "G: avg=1.3018, std=0.1625\n",
      "d: avg=0.4141, std=0.0800\n",
      "W1: avg=926.6028, std=344.1253\n",
      "W2: avg=520.4423, std=265.0368\n",
      "W3: avg=266.7374, std=168.0284\n",
      "W4: avg=108.3011, std=76.1029\n",
      "W5: avg=51.0717, std=39.9568\n",
      "W6: avg=21.2756, std=19.6595\n",
      "W7: avg=6.6824, std=8.6810\n",
      "W8: avg=1.2447, std=2.8466\n",
      "D1: avg=212.4107, std=93.6921\n",
      "D2: avg=92.6285, std=49.8739\n",
      "D3: avg=37.6593, std=23.0159\n",
      "D4: avg=20.6663, std=14.9053\n",
      "D5: avg=12.7539, std=10.2231\n",
      "D6: avg=8.3179, std=7.3247\n",
      "D7: avg=5.5792, std=5.2948\n",
      "D8: avg=3.5231, std=3.6363\n",
      "WO1: avg=55.5713, std=65.3263\n",
      "WO2: avg=15.8892, std=20.8064\n",
      "WO3: avg=5.0716, std=7.7796\n",
      "WO4: avg=0.9044, std=2.0466\n",
      "WO5: avg=0.0483, std=0.2059\n",
      "WO6: avg=0.0009, std=0.0118\n",
      "WN1: avg=315.0833, std=196.6747\n",
      "WN2: avg=130.2197, std=90.5947\n",
      "WN3: avg=59.7586, std=46.0096\n",
      "WN4: avg=23.9120, std=21.6047\n",
      "WN5: avg=6.5165, std=8.9286\n",
      "WN6: avg=0.9208, std=2.4489\n",
      "IW1: avg=0.0892, std=0.0816\n",
      "IW2: avg=0.2948, std=0.2160\n",
      "IW3: avg=0.6575, std=0.4529\n",
      "IW4: avg=0.8714, std=0.7031\n",
      "CW1: avg=2.3579, std=0.4126\n",
      "CW2: avg=1.3095, std=0.5851\n",
      "CW3: avg=0.6697, std=0.4124\n",
      "CW4: avg=0.2748, std=0.1921\n",
      "CW5: avg=0.1267, std=0.0971\n",
      "CW6: avg=0.0519, std=0.0489\n",
      "CW7: avg=0.0158, std=0.0222\n",
      "CW8: avg=0.0029, std=0.0076\n",
      "ID1: avg=0.0493, std=0.0410\n",
      "ID2: avg=0.1035, std=0.0788\n",
      "ID3: avg=0.1420, std=0.0970\n",
      "ID4: avg=0.1637, std=0.1239\n",
      "CD1: avg=0.5481, std=0.2146\n",
      "CD2: avg=0.2307, std=0.1039\n",
      "CD3: avg=0.0923, std=0.0522\n",
      "CD4: avg=0.0492, std=0.0339\n",
      "CD5: avg=0.0293, std=0.0225\n",
      "CD6: avg=0.0188, std=0.0161\n",
      "CD7: avg=0.0124, std=0.0116\n",
      "CD8: avg=0.0078, std=0.0080\n",
      "HL1: avg=3.9639, std=10.7651\n",
      "HL2: avg=3.2335, std=7.3331\n",
      "A: avg=3.9225, std=2.1307\n",
      "CP: avg=10.6478, std=22.7664\n",
      "POL: avg=25.6843, std=12.9810\n",
      "MW: avg=241.1878, std=117.8455\n",
      "FLEX: avg=1.0455, std=1.0107\n",
      "FLEX_RB: avg=0.1623, std=0.1166\n",
      "NCC: avg=0.0818, std=0.2958\n",
      "DIFF: avg=0.7192, std=0.2761\n",
      "SE: avg=10.3378, std=7.5639\n",
      "SE0: avg=7.7429, std=5.8731\n",
      "SE1: avg=2.5949, std=3.1686\n",
      "LOGP n-Oct: avg=2.4203, std=1.5918\n",
      "LOGP c-Hex: avg=1.1595, std=2.1580\n",
      "PSA: avg=43.9860, std=33.6593\n",
      "HSA: avg=350.7714, std=127.6221\n",
      "PSAR: avg=0.1103, std=0.0866\n",
      "PHSAR: avg=0.1366, std=0.1327\n",
      "LgD5: avg=1.1044, std=1.8160\n",
      "LgD6: avg=1.3477, std=1.7060\n",
      "LgD7: avg=1.6388, std=1.6203\n",
      "LgD7.5: avg=1.7793, std=1.6128\n",
      "LgD8: avg=1.9007, std=1.6343\n",
      "LgD9: avg=2.0412, std=1.7403\n",
      "LgD10: avg=2.0171, std=1.8871\n",
      "AUS7.4: avg=1.4232, std=0.7389\n",
      "%FU4: avg=52.2777, std=48.3077\n",
      "%FU5: avg=53.7184, std=48.0982\n",
      "%FU6: avg=56.0499, std=47.6363\n",
      "%FU7: avg=58.4823, std=46.3323\n",
      "%FU8: avg=62.6525, std=41.8231\n",
      "%FU9: avg=72.2083, std=35.4703\n",
      "%FU10: avg=78.9319, std=35.1333\n",
      "SOLY: avg=-2.7651, std=1.3941\n",
      "LgS3: avg=-1.0486, std=1.9187\n",
      "LgS4: avg=-1.2610, std=1.8414\n",
      "LgS5: avg=-1.4546, std=1.7998\n",
      "LgS6: avg=-1.7010, std=1.7251\n",
      "LgS7: avg=-1.9940, std=1.6366\n",
      "LgS7.5: avg=-2.1345, std=1.6135\n",
      "LgS8: avg=-2.2556, std=1.6120\n",
      "LgS9: avg=-2.3944, std=1.6664\n",
      "LgS10: avg=-2.3680, std=1.7731\n",
      "LgS11: avg=-2.2337, std=1.9164\n",
      "PB: avg=63.2397, std=24.1395\n",
      "VD: avg=0.2621, std=0.2649\n",
      "CACO2: avg=0.9242, std=0.4929\n",
      "SKIN: avg=-2.2103, std=0.9229\n",
      "MetStab: avg=67.3769, std=24.6941\n",
      "HTSflag: avg=0.0007, std=0.0133\n",
      "C1: avg=0.0149, std=0.0427\n",
      "C2: avg=0.0776, std=0.0793\n",
      "C3: avg=0.1546, std=0.0968\n",
      "C4: avg=0.4819, std=0.2544\n",
      "P2: avg=0.0044, std=0.0183\n",
      "P3: avg=0.0569, std=0.0698\n",
      "P4: avg=0.0931, std=0.1032\n",
      "P5: avg=0.0174, std=0.0299\n",
      "EMDIF: avg=5.9091, std=2.4484\n",
      "EMDIS: avg=3.4164, std=2.3499\n",
      "Sdry/S: avg=0.6653, std=0.2167\n",
      "Spol/S: avg=0.2563, std=0.1786\n",
      "FLEX_PT: avg=1.9270, std=2.2170\n",
      "PAINS: avg=0.0273, std=0.1631\n",
      "logBB: avg=0.0743, std=0.6964\n",
      "Class: avg=0.5636, std=0.4967\n",
      "Index(['V', 'S', 'R', 'G', 'd', 'W1', 'W2', 'W3', 'W4', 'W5',\n",
      "       ...\n",
      "       'P2', 'P3', 'P4', 'P5', 'EMDIF', 'EMDIS', 'Sdry/S', 'Spol/S', 'FLEX_PT',\n",
      "       'PAINS'],\n",
      "      dtype='object', length=122)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['Objects'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     23\u001b[39m y_classification = np.array(permeate)\n\u001b[32m     25\u001b[39m \u001b[38;5;28mprint\u001b[39m(X.columns )\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m \u001b[43mX\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mObjects\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[38;5;28mprint\u001b[39m()\n\u001b[32m     30\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mX.shape\u001b[39m\u001b[33m'\u001b[39m, X.shape)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf_gpu_env/lib/python3.11/site-packages/pandas/core/frame.py:5603\u001b[39m, in \u001b[36mDataFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   5455\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdrop\u001b[39m(\n\u001b[32m   5456\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   5457\u001b[39m     labels: IndexLabel | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5464\u001b[39m     errors: IgnoreRaise = \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   5465\u001b[39m ) -> DataFrame | \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5466\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   5467\u001b[39m \u001b[33;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[32m   5468\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   5601\u001b[39m \u001b[33;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[32m   5602\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5603\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5604\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5605\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5606\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5607\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5608\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5609\u001b[39m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5610\u001b[39m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5611\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf_gpu_env/lib/python3.11/site-packages/pandas/core/generic.py:4810\u001b[39m, in \u001b[36mNDFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   4808\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes.items():\n\u001b[32m   4809\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4810\u001b[39m         obj = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4812\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[32m   4813\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_inplace(obj)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf_gpu_env/lib/python3.11/site-packages/pandas/core/generic.py:4852\u001b[39m, in \u001b[36mNDFrame._drop_axis\u001b[39m\u001b[34m(self, labels, axis, level, errors, only_slice)\u001b[39m\n\u001b[32m   4850\u001b[39m         new_axis = axis.drop(labels, level=level, errors=errors)\n\u001b[32m   4851\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4852\u001b[39m         new_axis = \u001b[43maxis\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4853\u001b[39m     indexer = axis.get_indexer(new_axis)\n\u001b[32m   4855\u001b[39m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[32m   4856\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf_gpu_env/lib/python3.11/site-packages/pandas/core/indexes/base.py:7136\u001b[39m, in \u001b[36mIndex.drop\u001b[39m\u001b[34m(self, labels, errors)\u001b[39m\n\u001b[32m   7134\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mask.any():\n\u001b[32m   7135\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors != \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m7136\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask].tolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found in axis\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   7137\u001b[39m     indexer = indexer[~mask]\n\u001b[32m   7138\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.delete(indexer)\n",
      "\u001b[31mKeyError\u001b[39m: \"['Objects'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# romove from Objects column the _cXX suffix\n",
    "X['Objects'] = X['Objects'].apply(lambda x: re.sub(r'_c\\d+', '', x))\n",
    "# try to average X for each molecule (Objects)\n",
    "X_grouped = X.groupby('Objects').mean()\n",
    "X = X_grouped\n",
    "print()\n",
    "print('After grouping by molecule:')\n",
    "print('X.shape', X.shape)\n",
    "print()\n",
    "print(X.head())\n",
    "print(X.info())\n",
    "# print each X column everage and std deviation\n",
    "print()\n",
    "print('X columns average and std deviation:')\n",
    "for col in X.columns:\n",
    "    if col != 'Objects':\n",
    "        print(f'{col}: avg={X[col].mean():.4f}, std={X[col].std():.4f}')\n",
    "\n",
    "y_regression = np.array(X['logBB'])\n",
    "X.drop(['logBB'], axis=1, inplace=True)\n",
    "permeate = X['Class'].tolist()\n",
    "X.drop(['Class'], axis=1, inplace=True)\n",
    "y_classification = np.array(permeate)\n",
    "\n",
    "print(X.columns )\n",
    "\n",
    "X.drop(['Objects'], axis=1, inplace=True)\n",
    "\n",
    "print()\n",
    "print('X.shape', X.shape)\n",
    "print('y_regression.shape', y_regression.shape)\n",
    "print('y_classification.shape', y_classification.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_val, X_test, y_regression_train_val, \\\n",
    "    y_regression_test, y_classification_train_val, \\\n",
    "    y_classification_test = \\\n",
    "    train_test_split(X, y_regression, y_classification, \\\n",
    "                     test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_regression_train, \\\n",
    "    y_regression_val, y_classification_train, \\\n",
    "    y_classification_val = \\\n",
    "    train_test_split(X_train_val, y_regression_train_val, \\\n",
    "                     y_classification_train_val, \\\n",
    "                     test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2\n",
    "print('X_train.shape', X_train.shape)\n",
    "print('y_regression_train.shape', y_regression_train.shape)\n",
    "print('y_classification_train.shape', y_classification_train.shape)\n",
    "print('X_val.shape', X_val.shape)\n",
    "print('y_regression_val.shape', y_regression_val.shape)\n",
    "print('y_classification_val.shape', y_classification_val.shape)\n",
    "print('X_test.shape', X_test.shape)\n",
    "print('y_regression_test.shape', y_regression_test.shape)\n",
    "print('y_classification_test.shape', y_classification_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data using StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "Xscaler = StandardScaler()\n",
    "X_train_scaled = Xscaler.fit_transform(X_train.drop(['Objects'], axis=1))\n",
    "X_val_scaled = Xscaler.transform(X_val.drop(['Objects'], axis=1))\n",
    "X_test_scaled = Xscaler.transform(X_test.drop(['Objects'], axis=1))\n",
    "Yscaler = StandardScaler()\n",
    "y_regression_train_scaled = Yscaler.fit_transform(y_regression_train.reshape(-1, 1)).flatten()\n",
    "y_regression_val_scaled = Yscaler.transform(y_regression_val.reshape(-1, 1)).flatten()\n",
    "y_regression_test_scaled = Yscaler.transform(y_regression_test.reshape(-1, 1)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop highly correlated features using th X_train_scaled\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "threshold = 0.95\n",
    "# Create a DataFrame from the scaled data\n",
    "X_train_df = pd.DataFrame(X_train_scaled, columns=X_train.columns.drop('Objects'))\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "corr_matrix = X_train_df.corr().abs()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "# Find features with correlation greater than the threshold\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "X_train_df = X_train_df.drop(columns=to_drop)\n",
    "\n",
    "# Apply the same feature selection to validation and test sets\n",
    "X_val_df = pd.DataFrame(X_val_scaled, columns=X_val.columns.drop('Objects'))\n",
    "X_val_df = X_val_df.drop(columns=to_drop)\n",
    "X_test_df = pd.DataFrame(X_test_scaled, columns=X_test.columns.drop('Objects'))\n",
    "X_test_df = X_test_df.drop(columns=to_drop)\n",
    "\n",
    "X_train_np = X_train_df.astype(float).to_numpy()\n",
    "X_val_np = X_val_df.astype(float).to_numpy()\n",
    "X_test_np = X_test_df.astype(float).to_numpy()\n",
    "\n",
    "print('After removing highly correlated features:')\n",
    "print('X_train_np.shape', X_train_np.shape)\n",
    "print('  X_val_np.shape', X_val_np.shape)\n",
    "print(' X_test_np.shape', X_test_np.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "for ncomp in range(2, X_train_np.shape[1]-X_train_np.shape[1]%10):\n",
    "    pca = PCA(n_components=ncomp)\n",
    "    X_pca = pca.fit_transform(X_train_np)\n",
    "    totalexplained = sum(pca.explained_variance_ratio_)\n",
    "    print('ncomp %3d'%(ncomp), 'totalexplained %3.2f'%(totalexplained))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=36)\n",
    "pca.fit(X_train_np)\n",
    "X_train_np = pca.transform(X_train_np)\n",
    "print('X_train_np.shape', X_train_np.shape)\n",
    "X_test_np = pca.transform(X_test_np)\n",
    "print('X_test_np.shape', X_test_np.shape)\n",
    "X_val_np = pca.transform(X_val_np)\n",
    "print('X_val_np.shape', X_val_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, InputLayer, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping  # Import EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "adam = Adam(learning_rate=0.001)\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(InputLayer(shape=(X_train_np.shape[1],)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "# *** ADDED DROPOUT ***\n",
    "# This layer \"drops\" 50% of its neurons randomly during training,\n",
    "# forcing the model to learn more robust, general patterns.\n",
    "model.add(Dropout(0.5))  # Dropout layer with a 50% dropout rate\n",
    "\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=adam,\n",
    "              metrics=['mse'])\n",
    "\n",
    "# *** DEFINE EARLY STOPPING ***\n",
    "# This callback will monitor the 'val_loss'.\n",
    "# If the validation loss doesn't improve for 5 epochs ('patience=5'),\n",
    "# it will stop the training and restore the best weights.\n",
    "early_stopper = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# --- Train the Model ---\n",
    "# We increased epochs to 100, but EarlyStopping will find the best one.\n",
    "history = model.fit(\n",
    "    X_train_np, y_regression_train_scaled,\n",
    "    epochs=200,  # Train for more epochs\n",
    "    batch_size=64,\n",
    "    verbose=1,\n",
    "    validation_data=(X_val_np, y_regression_val_scaled),\n",
    "    callbacks=[early_stopper]  # *** ADDED CALLBACK ***\n",
    ")\n",
    "\n",
    "endtrain = timeit.default_timer()\n",
    "print('Time train %8.3f s' % (endtrain - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"min loss: \", min(history.history['loss']))\n",
    "print(\"min val_loss: \", min(history.history['val_loss']))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_test = model.predict(X_test_np)\n",
    "Y_pred_test = Yscaler.inverse_transform(Y_pred_test).flatten()\n",
    "test_rmse = np.sqrt(mean_squared_error(y_regression_test, Y_pred_test))\n",
    "print('Test_rmse: ', test_rmse)\n",
    "Y_pred_train = model.predict(X_train_np)\n",
    "Y_pred_train = Yscaler.inverse_transform(Y_pred_train).flatten()\n",
    "train_rmse = np.sqrt(mean_squared_error(y_regression_train, Y_pred_train))\n",
    "print('Train_rmse: ', train_rmse)\n",
    "Y_pred_val = model.predict(X_val_np)\n",
    "Y_pred_val = Yscaler.inverse_transform(Y_pred_val).flatten()\n",
    "val_rmse = np.sqrt(mean_squared_error(y_regression_val, Y_pred_val))\n",
    "print('Validation_rmse: ', val_rmse)\n",
    "plt.figure()\n",
    "plt.scatter(y_regression_test, Y_pred_test, label='Test data')\n",
    "plt.scatter(y_regression_train, Y_pred_train, label='Train data')\n",
    "plt.scatter(y_regression_val, Y_pred_val, label='Validation data')\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predictions')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPfP1whGRyG7s0AptBbkbyh",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tf_gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
