{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Modelling\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Tree Visualisation\n",
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import Image\n",
    "import graphviz\n",
    "\n",
    "df = pd.read_csv('./data/bbb.csv', sep=';')\n",
    "df = df[df['Objects'].str.contains('_c0')]\n",
    "df['Objects'] = df['Objects'].str.replace('_c0', '')\n",
    "df_label = pd.read_csv('./data/bbb_label.csv', sep=' ', header=None)\n",
    "# give a name to the columns \n",
    "df_label.columns = ['Objects', 'label']\n",
    "# select only row with the same name as in the label file\n",
    "df = df[df['Objects'].isin(df_label['Objects'])]\n",
    "df = df.set_index('Objects')\n",
    "df_label = df_label.set_index('Objects')\n",
    "# add all in a single dataframe\n",
    "df = df.join(df_label)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('label', axis=1)\n",
    "X = X.fillna(0)\n",
    "y = df['label']\n",
    "print(X.shape)\n",
    "CORRCUT = 0.95\n",
    "# remove highly correlated features \n",
    "corr_matrix = X.corr().abs()\n",
    "#print(np.triu(np.ones(corr_matrix.shape), \\\n",
    "#                                  k=1).astype(np.bool))\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), \\\n",
    "                                  k=1).astype(bool))\n",
    "#print(upper)\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > CORRCUT)]\n",
    "#for i in to_drop:\n",
    "#    print(f\"Removing {i} because of high correlation\")\n",
    "X = X.drop(X[to_drop], axis=1)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \\\n",
    "                    test_size=0.2, random_state=42)\n",
    "accuracys = []\n",
    "numoftrees = []\n",
    "for numofest in range(1, 100, 10):\n",
    "    rf = RandomForestClassifier(n_estimators=numofest, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    accuracys.append(acc)\n",
    "    numoftrees.append(numofest)\n",
    "    #print(f\"Accuracy for {numofest} trees:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot saccuracy vs number of trees\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(numoftrees, accuracys)\n",
    "plt.xlabel('Number of Trees')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs Number of Trees')\n",
    "plt.show()\n",
    "print(\"Max Accuracy:\", max(accuracys))\n",
    "bestnoftrees = numoftrees[accuracys.index(max(accuracys))]\n",
    "print(\"Number of Trees:\", bestnoftrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model with best number of trees\n",
    "rf = RandomForestClassifier(n_estimators=bestnoftrees, \\\n",
    "                            random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "# print out the max detpth used in the trees\n",
    "print(\"Max Depth:\", rf.max_depth)\n",
    "y_pred = rf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "# the same for the training set \n",
    "y_pred_train = rf.predict(X_train)\n",
    "print(\"Accuracy on training set:\", \\\n",
    "      accuracy_score(y_train, y_pred_train))\n",
    "print(\"Confusion Matrix on training set:\")\n",
    "print(confusion_matrix(y_train, y_pred_train))\n",
    "print(\"Precision on training set:\", \\\n",
    "      precision_score(y_train, y_pred_train))\n",
    "print(\"Recall on training set:\", \\\n",
    "      recall_score(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testaccuracy = []\n",
    "trainaccuracy = []\n",
    "for maxdepth in range(1, 10):\n",
    "    rf = RandomForestClassifier(n_estimators=bestnoftrees, \\\n",
    "                            max_depth=maxdepth, \\\n",
    "                            random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    testaccuracy.append(accuracy_score(y_test, y_pred))\n",
    "    y_pred_train = rf.predict(X_train)\n",
    "    trainaccuracy.append(accuracy_score(y_train, y_pred_train))\n",
    "\n",
    "plt.plot(range(1, 10), testaccuracy, label='Test')\n",
    "plt.plot(range(1, 10), trainaccuracy, label='Train')\n",
    "plt.xlabel('Max Depth')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs Max Depth')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "bestdepth = testaccuracy.index(max(testaccuracy))+1\n",
    "print (\"Max Accuracy:\", max(testaccuracy),\\\n",
    "        \"Max Depth:\", bestdepth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=bestnoftrees, \\\n",
    "                            max_depth=bestdepth, \\\n",
    "                            random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "# the same for the training set\n",
    "y_pred_train = rf.predict(X_train)\n",
    "print(\"Accuracy on training set:\", \\\n",
    "      accuracy_score(y_train, y_pred_train))\n",
    "print(\"Confusion Matrix on training set:\")\n",
    "print(confusion_matrix(y_train, y_pred_train))\n",
    "print(\"Precision on training set:\", \\\n",
    "      precision_score(y_train, y_pred_train))\n",
    "print(\"Recall on training set:\", \\\n",
    "        recall_score(y_train, y_pred_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    tree = rf.estimators_[i]\n",
    "    dot_data = export_graphviz(tree,\n",
    "                               feature_names=X_train.columns,  \n",
    "                               filled=True,  \n",
    "                               max_depth=2, \n",
    "                               impurity=False, \n",
    "                               proportion=True)\n",
    "    graph = graphviz.Source(dot_data)\n",
    "    display(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop logbb from the columns\n",
    "X = X.drop('LgBB', axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \\\n",
    "                    test_size=0.2, random_state=42)\n",
    "rf = RandomForestClassifier(n_estimators=bestnoftrees, \\\n",
    "                            max_depth=bestdepth, \\\n",
    "                            random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "# the same for the training set\n",
    "y_pred_train = rf.predict(X_train)\n",
    "print(\"Accuracy on training set:\", \\\n",
    "      accuracy_score(y_train, y_pred_train))\n",
    "print(\"Confusion Matrix on training set:\")\n",
    "print(confusion_matrix(y_train, y_pred_train))\n",
    "print(\"Precision on training set:\", \\\n",
    "      precision_score(y_train, y_pred_train))\n",
    "print(\"Recall on training set:\", \\\n",
    "        recall_score(y_train, y_pred_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    tree = rf.estimators_[i]\n",
    "    dot_data = export_graphviz(tree,\n",
    "                               feature_names=X_train.columns,  \n",
    "                               filled=True,  \n",
    "                               max_depth=2, \n",
    "                               impurity=False, \n",
    "                               proportion=True)\n",
    "    graph = graphviz.Source(dot_data)\n",
    "    display(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the roc curve using a RF regressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import auc\n",
    "lb = LabelBinarizer()\n",
    "y_train_bin = lb.fit_transform(y_train)\n",
    "y_test_bin = lb.transform(y_test)\n",
    "rf = RandomForestRegressor(n_estimators=bestnoftrees, \\\n",
    "                            max_depth=bestdepth, \\\n",
    "                            random_state=42)\n",
    "rf.fit(X_train, y_train_bin)\n",
    "y_pred = rf.predict(X_test)\n",
    "#print(y_pred)\n",
    "fpr, tpr, thresholds = roc_curve(y_test_bin, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, label='AUC = %0.2f' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(\"AUC:\", roc_auc_score(y_test_bin, y_pred))\n",
    "\n",
    "# the same for the training set\n",
    "y_pred_train = rf.predict(X_train)\n",
    "fpr, tpr, thresholds = roc_curve(y_train_bin, y_pred_train)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, label='AUC = %0.2f' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(\"AUC on training set:\", roc_auc_score(y_train_bin, y_pred_train))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
